


package org.lsst.sal;
import org.apache.kafka.clients.admin.*;
import org.apache.kafka.common.KafkaFuture;
import org.apache.kafka.clients.publisher.* 
import org.apache.kafka.clients.consumer.* 
import org.apache.kafka.common.serialization.StringDeserializer;  
import java.time.Duration;  
import java.util.Arrays;  
import java.util.Collections;  
import java.util.Properties;  
import org.lsst.sal.salActor;
import org.lsst.sal.salUtils;
import java.util.Random;
import java.util.StringTokenizer;
import lsst.sal.SALData.*

// INSERT SAL IMPORTS

public class SAL_SALData {

	private DomainParticipant participant;
	private Topic topic;
        private Topic topic2;
 
        private String server;
	private Publisher publisher;
	private Subscriber subscriber;
	private String typeName;
	private String typeName2;
	private String partitionName;
        private Boolean hasReader;
        private Boolean hasWriter;
        private Boolean hasEventReader;
        private Boolean hasEventWriter;
        private Boolean hasProcessor;
        private Boolean hasCommand;
        private int debugLevel;
        private int sndSeqNum;
        private int rcvSeqNum;
        private int rcvOrigin;
        private int historySync;
        private String rcvIdentity;
        private int subsystemID;
        private int origin;
        private String domainName;
        private String partitionPrefix;
        private int lastActor_telemetry;
        private int lastActor_command;
        private int lastActor_event;
        private String CSC_identity;
        private String authorizedUsers;
        private String nonAuthorizedCSCs;
        private Boolean authListEnabled;

        salUtils salUtil = new salUtils();
        salActor[] sal = new salActor[SAL__ACTORS_MAXCOUNT];

// INSERT TYPE SUPPORT      


        public int getActorIndex (String topicName) {
          for (int i=0; i<SAL__ACTORS_MAXCOUNT;i++) {
             if ( topicName.length() == sal[i].topicName.length() )  {
                if ( topicName.equals(sal[i].topicName) )  {
                   return i;
                }
             }
          }
          throw new RuntimeException("Unknown Topic");
        }


/** Sets up the Kafka Publisher support for the named Kafka type
  @param topicName is the name of the Kafka topic
  @throws RuntimeException if the topic is not defined
 */    
	public int salTelemetryPub(String topicName)
	{
	  int actorIdx = -1;
	  int status = 0;

	  actorIdx = getActorIndex(topicName);
	  if (actorIdx > -1) {
	     salTelemetryPub(actorIdx);
	  } else {
             throw new RuntimeException("Unknown Topic");
	  }
	  return status;
	}

/** Sets up the Kafka Subscriber support for the named Kafka type
  @param topicName is the name of the Kafka topic
  @throws RuntimeException if the topic is not defined
 */    
	public int salTelemetrySub(String topicName)
	{
	  int actorIdx = -1;
	  int status = 0;

	  actorIdx = getActorIndex(topicName);
	  if (actorIdx > -1) {
	     salTelemetrySub(actorIdx);
	  } else {
             throw new RuntimeException("Unknown Topic");
	  }
	  return status;
	}


/** Sets up the Kafka Publisher support for the indexed SAL Actor
  @param actorIdx is the index of the Kafka topic's salActor
 */    
        public int salTelemetryPub(int actorIdx)
	{
		String partitionName = domainName;

		// create Type
		salTypeSupport(actorIdx);

		// create Publisher
		createPublisher();

		// create Topic
		createTopic(actorIdx);

		sal[actorIdx].isWriter = true;
                return SAL__OK;
        }


        

/** Sets up the Kafka Subscriber support for the indexed SAL Actor
  @param actorIdx is the index of the Kafka topic's salActor
 */    
        public int salTelemetrySub(int actorIdx)
	{
		String partitionName = domainName;
                String errstr;
                
 
                if (!subscriber)
                  FATAL(errstr);
                 
                } else {
		  // create Type
		  salTypeSupport(actorIdx);

		  // create Subscriber
		  createSubscriber();

		  // create Topic
                  AvroSchema sal[actorIdx].topicType = avroMapper.schemaFor(sal[actorIdx].topicHandle.class);

                  sal[actorIdx].isReader = true;
                }
                  
                return SAL__OK;
	}



/// Placeholder routine to be replaced by system wide logging once available
	public void logError(int status) 
	{
		System.out.println("=== ERROR return value = " + status); 
	}

/** Constructor for the SAL_SALData object.
  *
  @param aKey is used to specify the index of an indexed component, or 0 for non-indexed ones
  @param identity is used to specify the private_identity of a commander

 */
        
        public SAL_SALData(int aKey, String identity)
	{
                if (identity == null) {
                   CSC_identity = String.format("SALData:%d" , aKey);
                } else {
                   CSC_identity = String.format("%s" , identity);
                }
		initSalEnvironment(aKey);
	}

        public SAL_SALData(int aKey)
	{
                CSC_identity = String.format("SALData:%d" , aKey);
		initSalEnvironment(aKey);
	}

        public SAL_SALData(String identity)
	{
                if (identity == null) {
                  CSC_identity = "SALData";
                } else {
                  CSC_identity = String.format("%s" , identity);
                }
		initSalEnvironment(0);
	}
	public SAL_SALData()
	{
                CSC_identity = "SALData";
		initSalEnvironment(0);
	}


/** Environment setup for a SAL_SALData object.
  *
  * + LSST_KAFKA_HISTORYSYNC is the maximum number of seconds to wait to obtain historical messages on a topic
  *
  @param aKey is used to specify the index of an indexed component, or 0 for non-indexed ones
 */
        public void initSalEnvironment(int aKey)
	{
 	       Random randGen = new java.util.Random();
               String pname = System.getenv("LSST_KAFKA_PREFIX");
               String kport = System.getenv("LSST_KAFKA_BROKER_PORT");
               String khost = System.getenv("LSST_KAFKA_HOST");
               String sname = System.getenv("LSST_KAFKA_HISTORYSYNC");
               String aname = System.getenv("LSST_KAFKA_ENABLE_AUTHLIST");
               String schemaRegistry = System.getenv("LSST_KAFKA_SCHEMA_REGISTRY");
               String securityProtocol = System.getenv("LSST_KAFKA_SECURITY_PROTOCOL");
               String securityMechanism = System.getenv("LSST_KAFKA_SECURITY_MECHANISM");
               String securityUserName = System.getenv("LSST_KAFKA_SECURITY_USERNAME");
               String securityPassword = System.getenv("LSST_KAFKA_SECURITY_PASSWORD");
               if (pname != null) {
                   partitionPrefix = pname;
               } else {
                   throw new RuntimeException("ERROR : Cannot find envvar LSST_KAFKA_PREFIX");
               }
               server = khost + ":" + kport;
               configuration.put("bootstrap.servers, server);
               configuration.put("schema.registry.url", schemaRegistry );
               configuration.put("kafka.security.protocol",securityProtocol);
               configuration.put("kafka.sasl.mechanism",securityMechanism);
               configuration.put("kafka.sasl.username",securityUserName);
               configuration.put("kafka.sasl.password",securityPassword);   
       	
               if (hname == null) {
                   historySync = 0;
                } else {
                   historySync = Integer.parseInt(hname);
                }
                authListEnabled = false;
                if (aname != null) {
                  if (Integer.valueOf(aname) == 1) {
                    authListEnabled = true;
                  } 
                }
                origin = (int)randGen.nextInt(99999999);
		hasReader = false;
		hasWriter = false;
		hasCommand = false;
		hasEventReader = false;
		hasEventWriter = false;
		hasProcessor = false;
		subsystemID = aKey;
		debugLevel = 0;
                System.loadLibrary("salUtils");
                initSalActors();
	}


/** Get the time from the system. The TAI time will be used, which assumes that the kernel 
  * leap seconds offset has been correctly set. The getLeapSeconds method can be used to 
  * do a simple sanity check
  @return The current TAI system time
 */
	public double getCurrentTime()
	{
  		double ts = salUtil.getTAISeconds();
		return ts;
	}



// INSERT CMDALIAS SUPPORT  for issueCommand and acceptCommand  



	public int cancelCommand( int cmdSeqNum )
	{
	   int status = 0;
	   return status;
	}


	public int abortCommand( int cmdSeqNum )
	{
	   int status = 0;
	   return status;
	}

        public static final int SAL__SLOWPOLL= 		   1;
        public static final int SAL__OK = 		   0;
        public static final int SAL__ERR = 		  -1;
        public static final int SAL__ERROR = 		  -1;
        public static final int SAL__NO_UPDATES = 	-100;
        public static final int SAL__LOG_ROUTINES = 	   1;
        public static final int SAL__CMD_ACK =      	 300;
        public static final int SAL__CMD_INPROGRESS = 	 301;
        public static final int SAL__CMD_STALLED =    	 302;
        public static final int SAL__CMD_COMPLETE =   	 303;
        public static final int SAL__CMD_NOPERM =   	-300;
        public static final int SAL__CMD_NOACK =    	-301;
        public static final int SAL__CMD_FAILED =   	-302;
        public static final int SAL__CMD_ABORTED =  	-303;
        public static final int SAL__CMD_TIMEOUT =  	-304;
        public static final int SAL__DATA_AVAIL	=	400;
        public static final int SAL__DEADLINE_MISS =	401;
        public static final int SAL__INCOMPAT_QOS =	402;
        public static final int SAL__SAMPLE_REJ	=	403;
        public static final int SAL__LIVELINESS_CHG =	404;
        public static final int SAL__SAMPLELOST	=	405;
        public static final int SAL__SUBSCR_MATCH =	406;
        public static final int SAL__STATE_DISABLED = 	1;
        public static final int SAL__STATE_ENABLED = 	2;
        public static final int SAL__STATE_FAULT = 	3;
        public static final int SAL__STATE_OFFLINE = 	4;
        public static final int SAL__STATE_STANDBY = 	5;
        public static final int SAL__STATE_COUNT = 	5;





// INSERT EVENTALIAS SUPPORT



/// Set the debug message output verbosity level for this SAL_SALData object
	public int setDebugLevel( int level )
	{
           int status = 0;
	   debugLevel = level;
	   return status;	
	}

/// Get the current value of the debug message verbosity level for this SAL_SALData object
	public int getDebugLevel( int level )
	{
	   return debugLevel;
	}

/// Get the current IP address
	public int getOrigin()
	{
	   int status = 0;
	   return status;
	}

/// Generic method to read the value of a SAL_SALData object internal state
	public int getProperty(String property, String value)
	{
	   int status = SAL__OK;
	   value = "UNKNOWN";
	   if (status != SAL__OK) {
	      if (debugLevel >= SAL__LOG_ROUTINES) {
	          logError(status);
	      }
	   }
	   return status;
	}

/// Generic method to set the value of a SAL_SALData object internal state
	public int setProperty(String property, String value)
	{
           int status = SAL__OK;
	   if (status != SAL__OK) {
	      if (debugLevel >= SAL__LOG_ROUTINES) {
	          logError(status);
	      }
	   }
	   return status;
	}
 

/// Close down the Kafka support for this SAL_SALData object
	public void salShutdown()
	{
          if (participant != null) {
             participant = null;
          }
	}


/** Sets up the Kafka Subscriber support for the named Kafka event topic
  @param topicName is the name of the Kafka topic
  @throws RuntimeException if the topic is not defined
 */    
	public int salEventSub(String topicName)
	{
		int status = SAL__ERROR;
                int actorIdx = getActorIndex(topicName);
                if ( actorIdx < 0) {
                  throw new RuntimeException("Unknown Topic");
		}
		status = salTelemetrySub(actorIdx);
                sal[actorIdx].isEventReader = true;
		return status;
	}

/** Sets up the Kafka Publisher support for the named Kafka event topic
  @param topicName is the name of the Kafka topic
  @throws RuntimeException if the topic is not defined
 */    
	public int salEventPub(String topicName)
	{
		int status = SAL__ERROR;
                int actorIdx = getActorIndex(topicName);
                if ( actorIdx < 0) {
                  throw new RuntimeException("Unknown Topic");
		}
		status = salTelemetryPub(actorIdx);
                sal[actorIdx].isEventWriter = true;
		return status;
	}



	public void createTopic(int actorIdx) {
		int status = -1;
                if (debugLevel > 1) {
  		  System.out.println("=== [createTopic] : topicName " + sal[actorIdx].topicName + " type = " + sal[actorIdx].typeName);
                }
		sal[actorIdx].topic = consumer.subscribe(Collections.singleton(sal[actorIdx].topicName));
	}

	public void createTopic2(int actorIdx) {
		int status = -1;
                if (debugLevel > 1) {
		  System.out.println("=== [createTopic2] : topicName " + sal[actorIdx].topicName + " type = " + sal[actorIdx].typeName2);
                }
		sal[actorIdx].topic2 = consumer.subscribe(Collections.singleton(sal[actorIdx].topicName));
	}

	public void createTopic(int actorIdx, String topicName) {
		int status = -1;
                if (debugLevel > 1) {
		  System.out.println("=== [createTopic] : topicName " + topicName + " type = " + sal[actorIdx].typeName);
                }
		sal[actorIdx].topic = consumer.subscribe(Collections.singleton(sal[actorIdx].topicName));
	}

	public void createTopic2(int actorIdx, String topicName) {
		int status = -1;
                if (debugLevel > 1) {
		  System.out.println("=== [createTopic2] : topicName " + topicName + " type = " + sal[actorIdx].typeName2);
                }

		sal[actorIdx].topic2 = consumer.subscribe(Collections.singleton(sal[actorIdx].topicName));
	}



	public void deleteTopics() {
            for (int i=0;  i<SAL__ACTORS_MAXCOUNT; i++) {
             if (sal[i] != null) {
              if (sal[i].topic != null) {
		  sal[i].topic = null;
              }
              if (sal[i].topic2 != null) {
		  sal[i].topic2 = null;
              }
             }
            }
	}


	public void createPublisher() {
	   if (publisher == null ) {
                configuration.put("key.serializer", AVRO_SERIALIZER_CLASS);
    	        configuration.put("value.serializer", AVRO_SERIALIZER_CLASS);
    	        publisher = new KafkaPublisher<>(properties);
                final AvroMapper avroMapper = new AvroMapper();
           }
	}


	public void deletePublisher() {
            if (publisher != null) {
		publisher  = null;
            }
            for (int i=0;  i<SAL__ACTORS_MAXCOUNT; i++) {
                   if (sal[i] != null) {
                      if (sal[i].publisher != null) {
		         sal[i].publisher = null;
                      }
                   }
            }
	}


	public void createSubscriber() {
	   if (subscriber == null ) {
        	configuration.put(ConsumerConfig.GROUP_ID_CONFIG, "LSST");
            	configuration.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, KafkaAvroDeserializer.class);
        	configuration.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, KafkaAvroDeserializer.class);
        	configuration.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        	configuration.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
                subscriber = new KafkaConsumer<>(properties);
           }
	}



	public void deleteSubscriber() {
                if (subscriber != null) {
  		   subscriber = null;
                }
                for (int i=0;  i<SAL__ACTORS_MAXCOUNT; i++) {
                   if (sal[i] != null) {
                      if (sal[i].subscriber != null) {
		         sal[i].subscriber = null;
                      }
                   }
                }
	}


}

