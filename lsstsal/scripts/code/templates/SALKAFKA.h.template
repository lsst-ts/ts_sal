
#ifndef _SAL_SALDataMGR_
  #define _SAL_SALDataMGR_

  #include <string>
  #include <cassert>
  #include <sstream>
  #include <iostream>
  #include <fstream>
  #include <vector>
  #include <string.h>
  #include <stdlib.h>
  #include <stdio.h>
  #include <time.h>
  #include <sys/time.h>
  #include <sys/timex.h>
  #include <signal.h>
  #include <unistd.h>
  #include <cstdlib>
  #include <cstring>
  #include <getopt.h>
  #include <iomanip>
  
  #include "SAL_defines.h"
  #include <boost/optional/optional_io.hpp>
// INSERT TYPE INCLUDES

  #include "SAL_SALDataC.h"

  #include <librdkafka/rdkafkacpp.h>
  #include <librdkafka/rdkafka.h>
  #include <avro/Encoder.hh>
  #include <avro/Decoder.hh>
  #include <avro/Generic.hh>
  #include <avro/GenericDatum.hh>
  #include <avro/Specific.hh>
  #include <avro/Exception.hh>
  #include <avro/Compiler.hh>
  #include "libserdes/serdescpp-avro.h"
  #include <avro/Schema.hh>
  #include <avro/ValidSchema.hh>

  using namespace std;
  using namespace avro;
  using namespace RdKafka;

#ifndef _SAL_SALActorMGR_
  #define _SAL_SALActorMGR_

/// The maximum number of Actors for a SAL_SALData object, equal to the number of Kafka topic types for SALData
  #define SAL__ACTORS_MAXCOUNT	1000

/// The maximum length of a Actor (aka Kafka topic) name
  #define SAL__ACTORS_NAMESIZE	128


/** The SAL_SALData object is instantiated with an array of salActor data structures.
  * Each salActor maintains the state information for a single Kafka topic in the SALData namespace.
  * This includes Kafka datatypes , as well as SAL CSC specific information
 */ 
  struct salActor {
/// baseName holds the name of the SALData object
      char 			baseName[SAL__ACTORS_NAMESIZE];
/// topicName holds the root name of the Kafka topic
      char 			topicName[SAL__ACTORS_NAMESIZE];
/// topicName2 holds the root name of the Kafka topic
      char 			topicName2[SAL__ACTORS_NAMESIZE];
/// partition holds the Kafka partition to which the topic is associated with
      int		partition;
/// topicHandle holds the actual name of the Kafka topic with an AVRO versioned hash appended 
      char 			topicHandle[SAL__ACTORS_NAMESIZE];
/// sFilter is used to build the filtering pattern for indexed Kafka topics, for example HexapodID=2
      string 		sFilter;
/// typeName holds the Kafka type, in our case it is the same as the topicHandle
      string 		typeName;
/// typeName2 holds the complementary type of the ackCmd when typeName is a command topic
/// a commander needs an ackCmd subscriber , and a processor needs an ackCmd publisher
      string 		typeName2;
/// topic holds a pointer to the internal Kafka topic object
      RdKafka::Topic		*topic;
/// topic2 holds a pointer to the internal Kafka topic object
      RdKafka::Topic 		*topic2;
/// topic holds a pointer to the internal Kafka topic configuration object
      RdKafka::Conf		*topicConfiguration;
/// topic2 holds a pointer to the internal Kafka topic configuration object
      RdKafka::Conf	 	*topicConfiguration2;
/// publisher holds a pointer to the internal Kafka Publisher object
///      RdKafka::Publisher 	*publisher;
/// subscriber holds a pointer to the internal Kafka Subscriber object
    RdKafka::KafkaConsumer      *subscriber;
    std::string avroName;
    std::string avroName2;
    Serdes::Schema 		*avroSchema;
    Serdes::Schema 		*avroSchema2;
///    avro::ValidSchema 		avroSchema;
///    avro::ValidSchema 		avroSchema2;
    bool hasSchema;
/// isActive is true when the Actor has been connected to Kafka
      bool			isActive;
/// isReader is true when the Actor is a Kafka reader
      bool 			isReader;
/// isWriter is true when the Actor is a Kafka writer
      bool 			isWriter;
/// isCommand is true when the Actor is a managing a SAL commander
      bool 			isCommand;
/// isEventReader is true when the Actor is a managing a SAL event subscriber
      bool 			isEventReader;
/// isEventWriter is true when the Actor is a managing a SAL event publisher
      bool 			isEventWriter;
/// isCommand is true when the Actor is a managing a SAL command processor
      bool 			isProcessor;
/// debugLevel is the numerical level of verbosity controlling the output of debug messages
      int 			debugLevel;
/// sndSeqNum holds the sequence number of the most recent Kafka message sent for this topic
      int 			sndSeqNum;
/// cmdSeqNum holds the sequence number of the most recent Kafka command sent for this topic
      int                       cmdSeqNum;
/// sndSeqNum holds the sequence number of the most recent Kafka message received for this topic
      int 			rcvSeqNum;
/// rcvOrigin holds the IP address of the most recent Kafka message received for this topic
      int                       rcvOrigin;
/// rcvIdentity holds the private_identity filled from the last Kafka message received for this topic
      string 			rcvIdentity;
/// maxSamples is used to control the maximum number of Kafka messages received by getSample/getNextSample methods
      int			maxSamples;
/// error is the error field for the most recent ackCmd message (commands)
      int			error;
/// ack is the ack field for the most recent ackCmd message (commands)
      int			ack;
/// activeidentity is the private_identity field of the most recent command
      string			activeidentity;
/// activeorigin is the private_origin field of the most recent command
      int activeorigin;
/// activecmdid is the command sequence number of the most recent command
      int			activecmdid;
/// timeout is the number of seconds the command is expected to take to execute
      double			timeout;
/// result is the text message result of the most recent command
      string			result;
/// sndStamp is the TAI timestamp of the most recent command sent
      double	 		sndStamp;
/// rcvStamp is the TAI timestamp of the most recent command received
      double			rcvStamp;
/// sampleAge is the time in seconds between command send and receive
      double			sampleAge;
/// historyDepth is the maximum size (in samples) of the Kafka message cache for the topic
      long                      historyDepth;
/// historyOffset is current offset the Kafka message store for the topic
      long                      historyOffset;
  };
#endif

  class SAL_SALData
  {
      /* Generic Kafka entities */
      const std::string server;
      RdKafka::TopicPartition *tpartition;
      RdKafka::Conf *configuration;
      RdKafka::Conf *consumerConfiguration;
      RdKafka::Conf *topicConfiguration;
      RdKafka::Topic *topic;
      RdKafka::Topic *topic2;
      RdKafka::Producer *publisher;
      RdKafka::KafkaConsumer *subscriber;
      RdKafka::Headers *headers;
      Serdes::Conf *serdesConfiguration;
      Serdes::Avro *serdes;
      Serdes::Schema *schema;
      std::string schema_name;
      std::string schema_def;
      int domain;
      int status;
      int participant;
      string typeName;
      string typeName2;
      string sFilter;
      bool hasReader;
      bool hasWriter;
      bool hasCommand;
      bool hasEventReader;
      bool hasEventWriter;
      bool hasProcessor;
      int subsystemID;
      int debugLevel;
      int cmdSeqNum;
      int sndSeqNum;
      int rcvSeqNum;
      int rcvOrigin;
      string rcvIdentity;
      int historySync;
      double rcvdTime;
      salU64  origin;
      char domainName[128];
      int partition = -1;
      salActor sal[SAL__ACTORS_MAXCOUNT];
      int lastActor_telemetry;
      int lastActor_command;
      int lastActor_event;
      char *pname;
      char *aname;
      char *sname;
      char *kport;
      char *khost;
      char *securityProtocol;
      char *securityMechanism;
      char *securityUserName;
      char *securityPassword;
      char *schemaRegistry;
      char *localSchemaDir;
      char *kafkaProducerWaitAcks;

///   Holds the private_identity of this SAL Object, set at creation
      char CSC_identity[128];
    public:

/** Constructor for the SAL_SALData object.
  *
  @param aKey is used to specify the index of an indexed component, or 0 for non-indexed ones
  @param identity is used to specify the private_identity of a commander

 */
     SAL_SALData(int aKey, char *identity);
     SAL_SALData(int aKey);
     SAL_SALData(char *identity);
     SAL_SALData();

/** Environment setup for a SAL_SALData object.
  *
  * + LSST_Kafka_DOMAIN is the name of the partition being used
  * + LSST_Kafka_IP is the IP address of the Kafka ethernet interface
  * + LSST_Kafka_HISTORYSYNC is the maximum number of seconds to wait to obtain historical messages on a topic
  *
  @param aKey is used to specify the index of an indexed component, or 0 for non-indexed ones
 */
     void initSalEnvironment(int aKey);

/** Sets up the Kafka Publisher support for the named Kafka type
  @param topicName is the name of the Kafka topic
  @throws std::runtime_error if the topic is not defined
 */    
      salReturn salTelemetryPub(char *topicName);

/** Sets up the Kafka Subscriber support for the named Kafka type
  @param topicName is the name of the Kafka topic
  @throws std::runtime_error if the topic is not defined
 */    
      salReturn salTelemetrySub(char *topicName);

/// Returns of vector::string consisting of the topic names of all SAL_SALData telemetry topics
      std::vector<std::string> getTelemetryNames();

/// Returns of vector::string consisting of the topic names of all SAL_SALData command topics
      std::vector<std::string> getCommandNames();

/// Returns of vector::string consisting of the topic names of all SAL_SALData logevent topics
      std::vector<std::string> getEventNames();

// INSERT CMDALIAS SUPPORT  for issueCommandC and acceptCommandC, acceptAnyCommand

// INSERT EVENTALIAS SUPPORT for getEventC and logEventC , getAnyEvent

// INSERT TYPE SUPPORT  

/// Return the text string corresponding to a Kafka internal error code
///      string getErrorName(RdKafka::ErrorCode *status);

/// Check the status of any Kafka methods return code, can cause the program to throw Kafka exceptions
///      void checkStatus(RdKafka::ErrorCode *status, const char *info);

/** Get the time from the system. The TAI time will be used, which assumes that the kernel 
  * leap seconds offset has been correctly set. The getLeapSeconds method can be used to 
  * do a simple sanity check
  @return The current TAI system time
 */
      double getCurrentTime();
      
/** Get the time from the system. The CLOCK_REALTIME (UTC) time will be used, which assumes that the kernel 
  * leap seconds offset has been correctly set. The getLeapSeconds method can be used to 
  * do a simple sanity check
  @return The current UTC system time
 */
      double getCurrentUTC();

/** Get the timestamp from the most recent Kafka message received for a topic
  @param Name of the topic as defined in the XML
  @return The TAI timestamp (private_rcvStamp) from the message
 */
      double getRcvdTime(char *topicName);

/** Get the sender timestamp from the most recent Kafka message received for a topic
  @param Name of the topic as defined in the XML
  @return The TAI timestamp (private_sndStamp) from the message
 */
      double getSentTime(char *topicName);

/// Returns the integer number of leap seconds that the kernel has set
      int getLeapSeconds();

/// Returns the current SAL version e.g. "4.1.0"
      static std::string getSALVersion();

/// Returns the current XML version e.g. "5.0.0"
      static std::string getXMLVersion();

/// Returns the current Kafka version e.g. "2.0.0"
      static std::string getKAFKAVersion();

/// Returns the current AVRO version e.g. "1.11.1"
      static std::string getAVROVersion();
      
/// Returns the current OSPL version e.g. "0.0.0"
      static std::string getOSPLVersion();

/** Sets up the Kafka data type low level support for the named Kafka type
  @param topicName is the name of the Kafka topic
  @throws std::runtime_error if the topic is not defined
 */    
      salReturn salTypeSupport(char *topicName);

///  Remove whitespace from the a string
     std::string removeSpaces(std::string list);

/// Set the debug message output verbosity level for this SAL_SALData object
      salReturn setDebugLevel( int level );

/// Get the current value of the debug message verbosity level for this SAL_SALData object
      int getDebugLevel( int level );

/// Get the current IP address
      int getOrigin();

/// Generic method to read the value of a SAL_SALData object internal state
      int getProperty(salCHAR *property, salCHAR *value);

/// Generic method to set the value of a SAL_SALData object internal state
      int setProperty(salCHAR *property, salCHAR *value);

/// Generic method to read the integer value of a SAL_SALData object internal state
      int getIntProperty(int actorIdx,salCHAR *property);

/// Generic method to read the double value of a SAL_SALData object internal state
      double getDblProperty(int actorIdx,salCHAR *property);

/// Generic method to read the boolean value of a SAL_SALData object internal state
      bool getBoolProperty(int actorIdx,salCHAR *property);

/** Set the value of maxSamples for the Actor specified
  @param actorIdx is the index into the salActors array
  @param n is the new number of maxSamples to use
 */
      void setMaxSamples(int actorIdx, int n);

/// Placeholder routine to be replaced by system wide logging once available
      void logError(salReturn status);
      std::string randomString(size_t length);

/// Close down the Kafka support for this SAL_SALData object
      void salShutdown();

      void createParticipant(const char *partitiontName);
      void createTopic(char *topicName);
      void createTopic2(char *topicName);
      void deletePublisher();
      void deleteTopics();
      void deleteSubscriber();
//      RdKafka::Producer getPublisher();
//      RdKafka::Consumer getSubscriber();
//      RdKafka::Topic getTopic();
//      DomainParticipant_ptr getParticipant();

      void initSalActors();
      salReturn salTelemetryPub(int actorIdx);
      salReturn salTelemetrySub(int actorIdx);
      salReturn salEventSub(char *topicName);
      salReturn salEventPub(char *topicName);
      int getActorIndex(char *topic);
      salReturn salTypeSupport(int actorIdx);
      salReturn salCommand(char *cmdAlias);
      salReturn salProcessor(char *cmdAlias);
      void checkSchema(int actorIdx);
      void createTopic(int actorIdx);
      void createTopic2(int actorIdx);
      void createTopic(int actorIdx, char *topicName);
      void createTopic2(int actorIdx, char *topicName);
      void createPublisher(int actorIdx);
      void createSubscriber(int actorIdx);
 //     RdKafka::Topic  getTopic(int actorIdx);
 //     RdKafka::Topic  getTopic2(int actorIdx);
      bool actorActive(int actorIdx);
      bool actorReader(int actorIdx);
      bool actorWriter(int actorIdx);
      bool actorCommand(int actorIdx);
      bool actorEventReader(int actorIdx);
      bool actorEventWriter(int actorIdx);
      bool actorProcessor(int actorIdx);


      ~SAL_SALData();
  };

#endif
